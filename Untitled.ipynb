{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[parse] url: https://www.tripadvisor.ca/Hotel_Review-g60982-d87016-Reviews-Hilton_Hawaiian_Village_Waikiki_Beach_Resort-Honolulu_Oahu_Hawaii.html?filterLang=en\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2c4314f11947>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;31m# get all reviews for 'url' and 'lang'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-2c4314f11947>\u001b[0m in \u001b[0;36mscrape\u001b[0;34m(url, lang)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'?filterLang='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-2c4314f11947>\u001b[0m in \u001b[0;36mparse\u001b[0;34m(session, url)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mnum_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'span'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'reviews_header_count'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mnum_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_reviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mnum_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "import requests             \n",
    "from bs4 import BeautifulSoup \n",
    "import csv                  \n",
    "import webbrowser\n",
    "import io\n",
    "\n",
    "def display(content, filename='output.html'):\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(content)\n",
    "        webbrowser.open(filename)\n",
    "\n",
    "def get_soup(session, url, show=False):\n",
    "    r = session.get(url)\n",
    "    if show:\n",
    "        display(r.content, 'temp.html')\n",
    "\n",
    "    if r.status_code != 200: # not OK\n",
    "        print('[get_soup] status code:', r.status_code)\n",
    "    else:\n",
    "        return BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "def post_soup(session, url, params, show=False):\n",
    "    '''Read HTML from server and convert to Soup'''\n",
    "\n",
    "    r = session.post(url, data=params)\n",
    "    \n",
    "    if show:\n",
    "        display(r.content, 'temp.html')\n",
    "\n",
    "    if r.status_code != 200: # not OK\n",
    "        print('[post_soup] status code:', r.status_code)\n",
    "    else:\n",
    "        return BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "def scrape(url, lang='ALL'):\n",
    "\n",
    "    # create session to keep all cookies (etc.) between requests\n",
    "    session = requests.Session()\n",
    "\n",
    "    session.headers.update({\n",
    "        'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:57.0) Gecko/20100101 Firefox/57.0',\n",
    "    })\n",
    "\n",
    "\n",
    "    items = parse(session, url + '?filterLang=' + lang)\n",
    "\n",
    "    return items\n",
    "\n",
    "def parse(session, url):\n",
    "    '''Get number of reviews and start getting subpages with reviews'''\n",
    "\n",
    "    print('[parse] url:', url)\n",
    "\n",
    "    soup = get_soup(session, url)\n",
    "\n",
    "    if not soup:\n",
    "        print('[parse] no soup:', url)\n",
    "        return\n",
    "\n",
    "    num_reviews = soup.find('span', class_='reviews_header_count').text \n",
    "    num_reviews = num_reviews[1:-1] \n",
    "    num_reviews = num_reviews.replace(',', '')\n",
    "    num_reviews = int(num_reviews) # convert text into integer\n",
    "    print('[parse] num_reviews ALL:', num_reviews)\n",
    "\n",
    "    url_template = url.replace('.html', '-or{}.html')\n",
    "    print('[parse] url_template:', url_template)\n",
    "\n",
    "    items = []\n",
    "\n",
    "    offset = 0\n",
    "\n",
    "    while(True):\n",
    "        subpage_url = url_template.format(offset)\n",
    "\n",
    "        subpage_items = parse_reviews(session, subpage_url)\n",
    "        if not subpage_items:\n",
    "            break\n",
    "\n",
    "        items += subpage_items\n",
    "\n",
    "        if len(subpage_items) < 5:\n",
    "            break\n",
    "\n",
    "        offset += 5\n",
    "\n",
    "    return items\n",
    "\n",
    "def get_reviews_ids(soup):\n",
    "\n",
    "    items = soup.find_all('div', attrs={'data-reviewid': True})\n",
    "\n",
    "    if items:\n",
    "        reviews_ids = [x.attrs['data-reviewid'] for x in items][::2]\n",
    "        print('[get_reviews_ids] data-reviewid:', reviews_ids)\n",
    "        return reviews_ids\n",
    "    \n",
    "def get_more(session, reviews_ids):\n",
    "\n",
    "    url = 'https://www.tripadvisor.com/OverlayWidgetAjax?Mode=EXPANDED_HOTEL_REVIEWS_RESP&metaReferer=Hotel_Review'\n",
    "\n",
    "    payload = {\n",
    "        'reviews': ','.join(reviews_ids), # ie. \"577882734,577547902,577300887\",\n",
    "        #'contextChoice': 'DETAIL_HR', # ???\n",
    "        'widgetChoice': 'EXPANDED_HOTEL_REVIEW_HSX', # ???\n",
    "        'haveJses': 'earlyRequireDefine,amdearly,global_error,long_lived_global,apg-Hotel_Review,apg-Hotel_Review-in,bootstrap,desktop-rooms-guests-dust-en_US,responsive-calendar-templates-dust-en_US,taevents',\n",
    "        'haveCsses': 'apg-Hotel_Review-in',\n",
    "        'Action': 'install',\n",
    "    }\n",
    "\n",
    "    soup = post_soup(session, url, payload)\n",
    "\n",
    "    return soup\n",
    "\n",
    "def parse_reviews(session, url):\n",
    "    '''Get all reviews from one page'''\n",
    "\n",
    "    print('[parse_reviews] url:', url)\n",
    "\n",
    "    soup =  get_soup(session, url)\n",
    "\n",
    "    if not soup:\n",
    "        print('[parse_reviews] no soup:', url)\n",
    "        return\n",
    "\n",
    "    hotel_name = soup.find('h1', id='HEADING').text\n",
    "\n",
    "    reviews_ids = get_reviews_ids(soup)\n",
    "    if not reviews_ids:\n",
    "        return\n",
    "\n",
    "    soup = get_more(session, reviews_ids)\n",
    "\n",
    "    if not soup:\n",
    "        print('[parse_reviews] no soup:', url)\n",
    "        return\n",
    "\n",
    "    items = []\n",
    "\n",
    "    for idx, review in enumerate(soup.find_all('div', class_='reviewSelector')):\n",
    "\n",
    "        badgets = review.find_all('span', class_='badgetext')\n",
    "        if len(badgets) > 0:\n",
    "            contributions = badgets[0].text\n",
    "        else:\n",
    "            contributions = '0'\n",
    "\n",
    "        if len(badgets) > 1:\n",
    "            helpful_vote = badgets[1].text\n",
    "        else:\n",
    "            helpful_vote = '0'\n",
    "        user_loc = review.select_one('div.userLoc strong')\n",
    "        if user_loc:\n",
    "            user_loc = user_loc.text\n",
    "        else:\n",
    "            user_loc = ''\n",
    "            \n",
    "        bubble_rating = review.select_one('span.ui_bubble_rating')['class']\n",
    "        bubble_rating = bubble_rating[1].split('_')[-1]\n",
    "\n",
    "        item = {\n",
    "            'review_body': review.find('p', class_='partial_entry').text,\n",
    "            'review_date': review.find('span', class_='ratingDate')['title'], # 'ratingDate' instead of 'relativeDate'\n",
    "        }\n",
    "\n",
    "        items.append(item)\n",
    "        print('\\n--- review ---\\n')\n",
    "        for key,val in item.items():\n",
    "            print(' ', key, ':', val)\n",
    "\n",
    "    print()\n",
    "\n",
    "    return items\n",
    "\n",
    "def write_in_csv(items, filename='results.csv',\n",
    "                  headers=['hotel name', 'review title', 'review body',\n",
    "                           'review date', 'contributions', 'helpful vote',\n",
    "                           'user name' , 'user location', 'rating'],\n",
    "                  mode='w'):\n",
    "\n",
    "    print('--- CSV ---')\n",
    "\n",
    "    with io.open(filename, mode, encoding=\"utf-8\") as csvfile:\n",
    "        csv_file = csv.DictWriter(csvfile, headers)\n",
    "\n",
    "        if mode == 'w':\n",
    "            csv_file.writeheader()\n",
    "\n",
    "        csv_file.writerows(items)\n",
    "        \n",
    "DB_COLUMN   = 'review_body'\n",
    "DB_COLUMN1 = 'review_date'\n",
    "\n",
    "start_urls = [\n",
    "    'https://www.tripadvisor.ca/Hotel_Review-g60982-d87016-Reviews-Hilton_Hawaiian_Village_Waikiki_Beach_Resort-Honolulu_Oahu_Hawaii.html',\n",
    "]\n",
    "\n",
    "lang = 'en'\n",
    "\n",
    "headers = [ \n",
    "    DB_COLUMN, \n",
    "    DB_COLUMN1, \n",
    "]\n",
    "\n",
    "for url in start_urls:\n",
    "\n",
    "    # get all reviews for 'url' and 'lang'\n",
    "    items = scrape(url, lang)\n",
    "\n",
    "    if not items:\n",
    "        print('No reviews')\n",
    "    else:\n",
    "        # write in CSV\n",
    "        filename = url.split('Reviews-')[1][:-5] + '__' + lang\n",
    "        print('filename:', filename)\n",
    "        write_in_csv(items, filename + '.csv', headers, mode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
